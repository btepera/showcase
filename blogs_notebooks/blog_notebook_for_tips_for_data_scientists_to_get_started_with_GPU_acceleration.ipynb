{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea25cdf7-bdbc-3cf1-0737-bc51675e3374",
    "_uuid": "fed5696c67bf55a553d6d04313a77e8c617cad99",
    "id": "e2TxdK7lM53J"
   },
   "source": [
    "# Tips for Data Scientists to Get Started with GPU Acceleration\n",
    "\n",
    "## Introduction\n",
    "This notebook showcases important functionalities that are important for data scientist and how RAPIDS accelerates workflows using its powerful suite of libraries and frameworks.  \n",
    "\n",
    "## Data We'll be Using\n",
    "We'll be exploring and augmenting the Titanic passenger demographic data set from Kaggle to showcase how you can apply these functions to yoru real world data.  The dataset used for this notebook can be downloaded from Kaggle and consists of a \n",
    "- [train](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/input?select=train.csv) dataset\n",
    "- [test](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/input?select=test.csv) dataset\n",
    "\n",
    "You will need to accept the terms of the competition before you can download it.  Once you do, please download both before continuing and put them into the same folder as you're running this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World: exploring cuDF and GPU Acceleration for pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext cudf.pandas loads the cuDF extension for Pandas, allowing the use of GPU-accelerated DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "d_hibjM0M53K",
    "outputId": "3d447dda-da99-4495-c2e9-64a3fdefd752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cudf.pandas extension is already loaded. To reload it, use:\n",
      "  %reload_ext cudf.pandas\n"
     ]
    }
   ],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries, read Titanic data, and concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eog51TtaB5Ij"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cupy as cp\n",
    "\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "concat = pd.concat([train, test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale up the dataset to demonstrate the advantage of GPU acceleration: the original Titanic dataset is too small, so we replicate it to simulate a dataset with 1 million rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "e7319668-86fe-8adc-438d-0eef3fd0a982",
    "_uuid": "13f38775c12ad6f914254a08f0d1ef948a2bd453",
    "id": "0HwIvMVJM53L",
    "outputId": "de15a613-e8ce-43b8-c57c-424b81b9bc06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 12)\n",
      "(1000000, 11)\n"
     ]
    }
   ],
   "source": [
    "target_rows = 1_000_000\n",
    "repeats = -(-target_rows // len(train))  # Ceiling division\n",
    "train_df = pd.concat([train] * repeats, ignore_index=True).head(target_rows)\n",
    "print(train_df.shape)  # (1000000, 2)\n",
    "\n",
    "repeats = -(-target_rows // len(test))  # Ceiling division\n",
    "test_df = pd.concat([test] * repeats, ignore_index=True).head(target_rows)\n",
    "print(test_df.shape)  # (1000000, 2)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cudf.pandas extension allows the execution of familiar pandas operations such as filtering, grouping, and merging, on GPUs without requiring a code change and/or rewrites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QWLwdRUWBuGn"
   },
   "outputs": [],
   "source": [
    "filtered_df = train_df[(train_df['Age'] > 30) & (train_df['Fare'] > 50)]\n",
    "grouped_df = train_df.groupby('Embarked')[['Fare', 'Age']].mean()\n",
    "additional_info = pd.DataFrame({\n",
    "\t'PassengerId': [1, 2, 3],\n",
    "\t'VIP_Status': ['No', 'Yes', 'No']\n",
    "})\n",
    "merged_df = train_df.merge(additional_info, on='PassengerId', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Performance: CPU and GPU Runtime Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The %%cudf.pandas.profile magic command profiles the calls executed on CPU and GPU and the time taken to execute them. The profiling output reveals that certain operations reverted to CPU execution, thereby indicating areas where GPU acceleration was not effectively utilized. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "0964832a-a4be-2d6f-a89e-63526389cee9",
    "_uuid": "97a845528ce9f76e85055a4bb9e97c27091f6aa1",
    "id": "OXGjZiFdM53N",
    "outputId": "08f7f964-4ac8-4d38-ffa3-57e0bb511492"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629592\n",
       "1       2  0.472810\n",
       "2       3  0.242378"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                         Total time elapsed: 0.092 seconds                                 </span>\n",
       "<span style=\"font-style: italic\">                                       5 GPU function calls in 0.014 seconds                               </span>\n",
       "<span style=\"font-style: italic\">                                       0 CPU function calls in 0.000 seconds                               </span>\n",
       "<span style=\"font-style: italic\">                                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                                       Stats                                               </span>\n",
       "<span style=\"font-style: italic\">                                                                                                           </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Function              </span>┃<span style=\"font-weight: bold\"> GPU ncalls </span>┃<span style=\"font-weight: bold\"> GPU cumtime </span>┃<span style=\"font-weight: bold\"> GPU percall </span>┃<span style=\"font-weight: bold\"> CPU ncalls </span>┃<span style=\"font-weight: bold\"> CPU cumtime </span>┃<span style=\"font-weight: bold\"> CPU percall </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ DataFrame.__getitem__ │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame.groupby     │ 1          │ 0.000       │ 0.000       │ 0          │ 0.000       │ 0.000       │\n",
       "│ GroupBy.mean          │ 1          │ 0.005       │ 0.005       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame.sort_values │ 1          │ 0.002       │ 0.002       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame.__repr__    │ 1          │ 0.005       │ 0.005       │ 0          │ 0.000       │ 0.000       │\n",
       "└───────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "\u001b[3m                                         Total time elapsed: 0.092 seconds                                 \u001b[0m\n",
       "\u001b[3m                                       5 GPU function calls in 0.014 seconds                               \u001b[0m\n",
       "\u001b[3m                                       0 CPU function calls in 0.000 seconds                               \u001b[0m\n",
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "\u001b[3m                                                       Stats                                               \u001b[0m\n",
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFunction             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mGPU percall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU ncalls\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU cumtime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCPU percall\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ DataFrame.__getitem__ │ 1          │ 0.001       │ 0.001       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame.groupby     │ 1          │ 0.000       │ 0.000       │ 0          │ 0.000       │ 0.000       │\n",
       "│ GroupBy.mean          │ 1          │ 0.005       │ 0.005       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame.sort_values │ 1          │ 0.002       │ 0.002       │ 0          │ 0.000       │ 0.000       │\n",
       "│ DataFrame.__repr__    │ 1          │ 0.005       │ 0.005       │ 0          │ 0.000       │ 0.000       │\n",
       "└───────────────────────┴────────────┴─────────────┴─────────────┴────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Python’s magic commands %%time %%timeit to time either the CPU and the GPU enabling you to benchmark specific code blocks by measuring their execution time and processor type. Because this environment is currently GPU enabled with cudf.pandas, and there currently is no simple way to turn it off, we can only show GPU accelerated runtimes. What we will do is run both examples from the blog with the GPU measurement. If you want to see the differences, you can still rerun the notebook and not load the cudf.pandas extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "da057efe-88f0-bf49-917b-bb2fec418ed9",
    "_uuid": "e328d9882affedcfc4c167aa5bb1ac132547558c",
    "id": "X7AM_T6XM53O",
    "outputId": "b9f64843-d53f-4213-af82-ed14f7ea5821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (1000000, 12) (1000000, 11) (1000000, 12) (1000000, 11)\n",
      "After (1000000, 10) (1000000, 9) (1000000, 10) (1000000, 9)\n",
      "CPU times: user 4.19 ms, sys: 12.8 ms, total: 17 ms\n",
      "Wall time: 16.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n",
    "\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "print(\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "df7f0cd4-992c-4a79-fb19-bf6f0c024d4b",
    "_uuid": "c916644bd151f3dc8fca900f656d415b4c55e2bc",
    "id": "piTSx5LPM53O",
    "outputId": "6d8c93f3-bff5-46ba-e16c-9886fe185470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.8 ms ± 372 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train_df['Title'], train_df['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying GPU Utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate a cupy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "9299523c-dcf1-fb00-e52f-e2fb860a3920",
    "_uuid": "24a0971daa4cbc3aa700bae42e68c17ce9f3a6e2",
    "id": "2v0-iydSM53P",
    "outputId": "0c9a7965-ccae-4884-d5eb-bc000ed7c8ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_ages = cp.zeros((2,3))\n",
    "guess_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether arrays are being processed on the CPU or GPU can be checked using the type command to differentiate between NumPy and CuPy arrays. If the output is np.array, the data is being processed on the CPU. If the output is cupy.ndarray, the data is being processed on the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7nihLFkTM53P",
    "outputId": "f04771d3-7231-416b-9787-5ae978fba0b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(guess_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the print command can confirm whether the GPU is being utilized and ensure that a cuDF DataFrame is being processed. The output specifies whether the fast path (cuDF) or slow path (pandas) is in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'pandas' (ModuleAccelerator(fast=cudf, slow=pandas))>\n"
     ]
    }
   ],
   "source": [
    "print(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands like df.info() can be used to inspect the structure of cuDF DataFrame and confirm that computations are GPU-accelerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "57dq01RxM53M",
    "outputId": "ed303fb1-65ad-446b-c1b7-9a7f4891e79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count    Dtype\n",
      "---  ------       --------------    -----\n",
      " 0   PassengerId  1000000 non-null  int64\n",
      " 1   Survived     1000000 non-null  int64\n",
      " 2   Pclass       1000000 non-null  int64\n",
      " 3   Name         1000000 non-null  object\n",
      " 4   Sex          1000000 non-null  object\n",
      " 5   Age          801349 non-null   float64\n",
      " 6   SibSp        1000000 non-null  int64\n",
      " 7   Parch        1000000 non-null  int64\n",
      " 8   Fare         1000000 non-null  float64\n",
      " 9   Embarked     997755 non-null   object\n",
      " 10  Title        1000000 non-null  object\n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 102.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
